{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Training a model to predict future personal consumption"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Scrape the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Gather data from https://fred.stlouisfed.org/ on Personal Consumption Expenditures (PCE) each month from January 2011 to May 2021."
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import necessary libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from selenium import webdriver\r\n",
    "from selenium.webdriver.common.keys import Keys\r\n",
    "import pandas as pd\r\n",
    "import datetime\r\n",
    "from dateutil.relativedelta import relativedelta"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a ChromeDriver Instance"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "options = webdriver.ChromeOptions()\r\n",
    "options.add_experimental_option('excludeSwitches', ['enable-logging'])\r\n",
    "driver = webdriver.Chrome(options=options)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "data = {'Month': [], 'PCE': []}\r\n",
    "date = datetime.datetime(2011, 1, 1)\r\n",
    "for i in range(125):\r\n",
    "    year = date.year\r\n",
    "    month = str(date.month).zfill(2)\r\n",
    "    url = \"https://fred.stlouisfed.org/release/tables?rid=54&eid=3220&od={}-{}-01#\".format(year,month)\r\n",
    "    driver.get(url)\r\n",
    "    pce = driver.find_element_by_xpath('//*[@id=\"release-elements-tree\"]/tbody/tr[1]/td[4]')\r\n",
    "    print(pce.text)\r\n",
    "    data['Month'].append(month + '-' + str(year))\r\n",
    "    data['PCE'].append(pce.text)\r\n",
    "    date = date + relativedelta(months=1)\r\n",
    "driver.quit()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create a Pandas DataFrame"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.DataFrame(data)\r\n",
    "df.to_pickle(\"df.pkl\") #saves the dataframe locally\r\n",
    "print(df)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing the Data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import the necessary libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os\r\n",
    "import datetime\r\n",
    "\r\n",
    "import IPython\r\n",
    "import IPython.display\r\n",
    "import matplotlib as mpl\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import seaborn as sns\r\n",
    "from sklearn.preprocessing import StandardScaler\r\n",
    "import tensorflow as tf\r\n",
    "\r\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\r\n",
    "mpl.rcParams['axes.grid'] = False"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inspect and Clean the Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df = pd.read_pickle(\"df.pkl\")\r\n",
    "df.shape"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "month_col = pd.to_datetime(df.pop('Month'), format='%m-%Y')\r\n",
    "month_col"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df[\"PCE\"] = df[\"PCE\"].str.replace(\",\",\"\").astype(float)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "plot_cols = ['PCE']\r\n",
    "plot_features = df[plot_cols]\r\n",
    "plot_features\r\n",
    "plot_features.index = month_col\r\n",
    "_ = plot_features.plot(subplots=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "df.describe().transpose()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "timestamp_s = month_col.map(datetime.datetime.timestamp)\r\n",
    "timestamp_s"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "n = len(df)\r\n",
    "train_df = df[0:int(n*0.7)]\r\n",
    "val_df = df[int(n*0.7):int(n*0.9)]\r\n",
    "test_df = df[int(n*0.9):]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Normalize the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "scaler = StandardScaler()\r\n",
    "train_df[['PCE']] = scaler.fit_transform(train_df[['PCE']])\r\n",
    "val_df[['PCE']] = scaler.fit_transform(val_df[['PCE']])\r\n",
    "test_df[['PCE']] = scaler.fit_transform(test_df[['PCE']])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Windowing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "class WindowGenerator():\r\n",
    "  def __init__(self, input_width, label_width, shift, train_df=train_df, val_df=val_df, test_df=test_df, label_columns=None):\r\n",
    "    # Store the raw data.\r\n",
    "    self.train_df = train_df\r\n",
    "    self.val_df = val_df\r\n",
    "    self.test_df = test_df\r\n",
    "\r\n",
    "    # Work out the label column indices.\r\n",
    "    self.label_columns = label_columns\r\n",
    "    if label_columns is not None:\r\n",
    "      self.label_columns_indices = {name: i for i, name in\r\n",
    "                                    enumerate(label_columns)}\r\n",
    "    self.column_indices = {name: i for i, name in\r\n",
    "                           enumerate(train_df.columns)}\r\n",
    "\r\n",
    "    # Work out the window parameters.\r\n",
    "    self.input_width = input_width\r\n",
    "    self.label_width = label_width\r\n",
    "    self.shift = shift\r\n",
    "\r\n",
    "    self.total_window_size = input_width + shift\r\n",
    "\r\n",
    "    self.input_slice = slice(0, input_width)\r\n",
    "    self.input_indices = np.arange(self.total_window_size)[self.input_slice]\r\n",
    "\r\n",
    "    self.label_start = self.total_window_size - self.label_width\r\n",
    "    self.labels_slice = slice(self.label_start, None)\r\n",
    "    self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\r\n",
    "\r\n",
    "  def __repr__(self):\r\n",
    "    return '\\n'.join([\r\n",
    "        f'Total window size: {self.total_window_size}',\r\n",
    "        f'Input indices: {self.input_indices}',\r\n",
    "        f'Label indices: {self.label_indices}',\r\n",
    "        f'Label column name(s): {self.label_columns}'])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def split_window(self, features):\r\n",
    "    inputs = features[:, self.input_slice, :]\r\n",
    "    labels = features[:, self.labels_slice, :]\r\n",
    "    if self.label_columns is not None:\r\n",
    "        labels = tf.stack(\r\n",
    "            [labels[:, :, self.column_indices[name]] for name in self.label_columns], axis = -1)\r\n",
    "    \r\n",
    "    inputs.set_shape([None, self.input_width, None])\r\n",
    "    labels.set_shape([None, self.label_width, None])\r\n",
    "\r\n",
    "    return inputs, labels\r\n",
    "\r\n",
    "WindowGenerator.split_window = split_window"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot(self, model=None, plot_col='PCE', max_subplots=3):\r\n",
    "  inputs, labels = self.example\r\n",
    "  plt.figure(figsize=(12, 8))\r\n",
    "  plot_col_index = self.column_indices[plot_col]\r\n",
    "  max_n = min(max_subplots, len(inputs))\r\n",
    "  for n in range(max_n):\r\n",
    "    plt.subplot(max_n, 1, n+1)\r\n",
    "    plt.ylabel(f'{plot_col} [normed]')\r\n",
    "    plt.plot(self.input_indices, inputs[n, :, plot_col_index],\r\n",
    "             label='Inputs', marker='.', zorder=-10)\r\n",
    "\r\n",
    "    if self.label_columns:\r\n",
    "      label_col_index = self.label_columns_indices.get(plot_col, None)\r\n",
    "    else:\r\n",
    "      label_col_index = plot_col_index\r\n",
    "\r\n",
    "    if label_col_index is None:\r\n",
    "      continue\r\n",
    "\r\n",
    "    plt.scatter(self.label_indices, labels[n, :, label_col_index],\r\n",
    "                edgecolors='k', label='Labels', c='#2ca02c', s=64)\r\n",
    "    if model is not None:\r\n",
    "      predictions = model(inputs)\r\n",
    "      plt.scatter(self.label_indices, predictions[n, :, label_col_index],\r\n",
    "                  marker='X', edgecolors='k', label='Predictions',\r\n",
    "                  c='#ff7f0e', s=64)\r\n",
    "\r\n",
    "    if n == 0:\r\n",
    "      plt.legend()\r\n",
    "\r\n",
    "  plt.xlabel('Month')\r\n",
    "\r\n",
    "WindowGenerator.plot = plot"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating the Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def make_dataset(self, data):\r\n",
    "    data = np.array(data, dtype=np.float32)\r\n",
    "    ds = tf.keras.preprocessing.timeseries_dataset_from_array(data=data, targets=None, sequence_length=self.total_window_size, sequence_stride=1, shuffle=True, batch_size=32,)\r\n",
    "    ds = ds.map(self.split_window)\r\n",
    "    return ds\r\n",
    "\r\n",
    "WindowGenerator.make_dataset = make_dataset"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "@property\r\n",
    "def train(self):\r\n",
    "    return self.make_dataset(self.train_df)\r\n",
    "\r\n",
    "@property\r\n",
    "def val(self):\r\n",
    "    return self.make_dataset(self.val_df)\r\n",
    "\r\n",
    "@property\r\n",
    "def test(self):\r\n",
    "    return self.make_dataset(self.test_df)\r\n",
    "\r\n",
    "@property\r\n",
    "def example(self):\r\n",
    "    # Example batch of inputs and labels\r\n",
    "    result = getattr(self, '_example', None)\r\n",
    "    if result is None:\r\n",
    "        result = next(iter(self.train))\r\n",
    "        self._example = result\r\n",
    "    return result \r\n",
    "\r\n",
    "WindowGenerator.train = train\r\n",
    "WindowGenerator.val = val\r\n",
    "WindowGenerator.test = test\r\n",
    "WindowGenerator.example = example   "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Building the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "OUT_STEPS = 3\r\n",
    "multi_window = WindowGenerator(input_width=6, label_width=OUT_STEPS, shift=OUT_STEPS)\r\n",
    "\r\n",
    "multi_window.plot()\r\n",
    "multi_window"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model = tf.keras.Sequential([\r\n",
    "    # Shape [batch, time, features] => [batch, lstm_units]\r\n",
    "    # Adding more `lstm_units` just overfits more quickly.\r\n",
    "    tf.keras.layers.GRU(256, return_sequences=True),\r\n",
    "    tf.keras.layers.SimpleRNN(128),\r\n",
    "    tf.keras.layers.Dropout(0.5),\r\n",
    "    # Shape => [batch, out_steps*features]\r\n",
    "    tf.keras.layers.Dense(32),\r\n",
    "    tf.keras.layers.Dense(OUT_STEPS),\r\n",
    "    # Shape => [batch, out_steps, features]\r\n",
    "    tf.keras.layers.Reshape([OUT_STEPS, 1])\r\n",
    "])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "MAX_EPOCHS = 20\r\n",
    "#early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, mode='min')\r\n",
    "model.compile(loss=tf.losses.MeanSquaredError(), optimizer=tf.optimizers.Adam(), metrics=[tf.metrics.MeanAbsoluteError()])\r\n",
    "model.fit(multi_window.train, epochs=MAX_EPOCHS, validation_data=multi_window.val, \r\n",
    "#callbacks=[early_stopping]\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "val_performance = model.evaluate(multi_window.val)\r\n",
    "val_performance"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.evaluate(multi_window.test, verbose=2)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "multi_window.val"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "multi_window.plot(model)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Saving the model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model.save('./model.h5')"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "06014547589a61cba93326921aada2d9c2673a5830f6a0df3bac1f8e2dca027d"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "metadata": {
   "interpreter": {
    "hash": "06014547589a61cba93326921aada2d9c2673a5830f6a0df3bac1f8e2dca027d"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}